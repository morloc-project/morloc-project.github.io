*This section is a work in progress*

The type system presented within this section is based the work of Dunfield and
Krishnaswami cite:[dunfield2013complete]. I preserved their naming conventions
where possible. Only the basic type checking and inference (System F) is
described here, the broader knowledge system introduced in the prior section
has not yet been implemented.

== Grammar

[latexmath]
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\[
\begin{align}
program   &\ :\ [statement]                         \sep & \text{brackets indicate a list of 0 or more} \\
statement &\ :\ \text{Source}\ x\ L                 \sep & \text{source var x from language L} \\
{}        &\ |\ \text{Import}\ v\ L                 \sep & \text{import all terms in module v} \\
{}        &\ |\ \text{Export}\ x                    \sep & \text{export var x from this module} \\
{}        &\ |\ x\ L ::\ A_L                        \sep & \text{signature for language L} \\
{}        &\ |\ x=expr\                             \sep & \text{declaration} \\
expr      &\ :\ (\ )                                \sep & \text{nothing} \\
{}        &\ |\ x                                   \sep & \text{a variable name} \\
{}        &\ |\ x\ ::\ [A_L]                        \sep & \text{annotation, only required for top-level expressions} \\
{}        &\ |\ \lambda x .\ expr                   \sep & \text{abstraction} \\
{}        &\ |\ expr\ expr                          \sep & \text{application} \\
{}        &\ |\ num\ |\ str\ |\ bool                \sep & \text{primitives} \\
{}        &\ |\ [e_1, ..., e_n]                     \sep & \text{list} \\
{}        &\ |\ (e_1, ..., e_n)                     \sep & \text{tuple} \\
{}        &\ |\ \braced{v_1=e_1,\ ...,\ v_n = e_n}  \sep & \text{record}
\end{align}
\]
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

This system departs from conventional lambda calculus by supporting multiple
languages in one program. It is designed to typecheck programs comprised of
many languages that share a common general type but that also have
language-specific, concrete types. Thus an expression may have the abstract
type `Num`, the C-type `double` and the python type `float`. Top-level
signatures can be used to specify the type of a term in different languages. A
term may be sourced from many different languages, thus latexmath:[x] is
multilingual.

[latexmath]
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\[
\begin{align}
\text{Types} \sep A,B,C\
       &: \alpha_L   \sep & \text{var in language L} \\
       &|\ A \rightarrow B              \sep & \text{function} \\
       &|\ \forall\ \alpha_L\ . A       \sep & \text{universal quantification over L} \\
       &|\ \alpha_L\ [A]                \sep & \text{parameterization} \\
       &|\ \ea_L [A] [d]       \sep & \text{existential (unsolved) variable with parameters and defaults}
\end{align}
\]
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Every type is associated with either the general language or a concrete
realization of the general type into a specific language.

|===
<| latexmath:[\text{TypeAnnotation} \sep A^{\bullet}, B^{\bullet}, C^{\bullet}\ := A \; L \; \braced{P_i}_{i=0}^m \; \braced{C_i}_{i=0}^n]
   +
   latexmath:[\text{Typeset} \sep \vec{A} := A_1^{\bullet},\ ...,\ A_n^{\bullet}]
|===

A type annotation couples a type in a given language with a set of properties
and constraints. The "properties" of the type are a set of n-ary relations
describing the type. These properties will eventually be used to implement the
equivalent of Haskell typeclasses. In the near future, I will add support for
casting functions that can be defined to allow automatic, language-specific,
handling for conversions between types (e.g., handling automatic conversions
from integers to doubles). The "constraints" are not yet implemented, but will
be a list of assertions that must be met. When possible, these constraints will
be evaluated statically, otherwise they will be translated into (possibly
optional) runtime assertions.

Typesets serve as collections of all that is known about a type as it is
represented across languages. Different languages may have different sets of
properties and constraints, they are unified only by a common name and complete
interchangeability.

== Declarative type system

*Coming soon (or late)*

== Algorithmic Rules

[latexmath]
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
\[
\begin{align}
\Gamma, \Delta & \ :\ [entry]              \sep & \text{ordered list of }entry \text{ items} \\
entry          & \ :\ \alpha_L             \sep & \text{type variable from language L} \\
               & \ |\ e = \vec{A}          \sep & \text{annotated expression}          \\
               & \ |\ \ea_L                \sep & \text{existential}                   \\
               & \ |\ \ea_L = t            \sep & \text{solved existential}            \\
               & \ |\ \mark{x}             \sep & \text{a named marker}                \\
               & \ |\ \text{Source}\ v\ L\ \sep & \text{source term from language L}   \\
\end{align}
\]
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

The context is a list storing type annotations, solved and unsolved existential
variables, markers, and source/export info.

The subtyping rules are adapted from cite:[dunfield2013complete].

I fleshed out the type system with containers (lists, tuples, records) and
parameterized types. The main change though is the addition of multi-lingual
support.

.Subtyping Rules
|===
<| latexmath:[\expr{\Gamma}{A\ <:\ B}{\Delta}] latexmath:[\quad\quad] Under input context latexmath:[\Gamma], type latexmath:[A] is a subtype of latexmath:[B], with output context latexmath:[\Delta]
^| latexmath:[\frac{}{\expr{\Gamma}{\alpha_L\ <:\ \alpha_L}{\Gamma}}] [green]+<:Var+
   latexmath:[\quad\quad]
   latexmath:[\frac{\packto{\beta_{L2}}{\alpha_{L1}}}{\expr{\Gamma}{\alpha_{L1}\ <:\ \beta_{L2}}{\Gamma}}] [blue]+<:AlienVar*+
   +
   + 
   latexmath:[\frac{}{\expr{\Gamma}{\ea_L\ <:\ \ea_L}{\Gamma}}] [green]+<:Exvar+
   latexmath:[\quad\quad]
   latexmath:[\frac{}{\expr{\Gamma}{\ea_{L1}\ <:\ \eb_{L2}}{\Gamma,\ \packto{\eb_{L2}}{\ea_{L1}}}}] [blue]+<:AlienExvar*+
   +
   +
   latexmath:[\frac{\Delta_1 = \Gamma \quad [\expr{\Delta_{i}}{A_i\ <:\ B_i}{\Delta_{i+1}}\]_{i=1}^n}{\expr{\Gamma}{\alpha_L\ [A_i\]_{i=1}^n <:\ \alpha_L\ [B_i\]_{i=1}^n}{\Delta_{n+1}}}] [blue]+<:App+
   latexmath:[\quad\quad]
   latexmath:[\frac{\Delta_1 = \Gamma \quad [ \expr{\Delta_i}{A_i\ <:\ B_i}{\Delta_{i+1}} \]_{i=1}^n \quad \packto{\beta_{L2}\ [B_i\]_{i=1}^m}{\alpha_{L1}\ [A_i\]_{i=1}^n}}{\expr{\Gamma}{\alpha_{L1}\ [A_i\]_{i=1}^n\ <:\ \beta_{L2}\ [B_i\]_{i=1}^n}{\Delta_{n+1}}}] [blue]+<:AppAlien+
   +
   +
   latexmath:[\frac{\packto{\alpha_{L1}\ [A_i\]_{i=1}^n}{\beta_{L2}}}{\expr{\Gamma}{\alpha_{L1}\ [A_i\]_{i=1}^n\ <:\ \beta_{L2}}{\Gamma}}] [blue]+<:AppAlienVarL+
   latexmath:[\quad\quad]
   latexmath:[\frac{\packto{\alpha_{L1}}{\beta_{L2}\ [B_i\]_{i=1}^n}}{\expr{\Gamma}{\alpha_{L1}\ <:\ \beta_{L2}\ [B_i\]_{i=1}^n}{\Gamma}}] [blue]+<:AppAlienVarR+
   +
   +
   latexmath:[\frac{\expr{\Gamma}{B_1\ <:\ A_1}{\Theta} \quad \expr{\Theta}{[\Theta\]A_2\ <:\ [\Theta\]B_2}{\Delta}}{\expr{\Gamma}{A_1 \rightarrow A_2\ <:\ B_1 \rightarrow B_2}{\Delta}}] [green]+<:→+
   +
   +
   latexmath:[\frac{\expr{\Gamma,\mark{\ea_L},\ea_L}{[\ea_L/\alpha_L\]A\ <:\ B}{\Delta,\mark{\ea_L},\Theta}}{\expr{\Gamma}{\forall \alpha_L . A\ <:\ B}{\Delta}}] [green]+<:∀L+
   latexmath:[\quad\quad]
   latexmath:[\frac{\expr{\Gamma,\alpha_L}{A<:B}{\Delta,\alpha_L,\Theta}}{\expr{\Gamma}{A <: \forall \alpha_L . B}{\Delta}}] [green]+<:∀R+
   +
   +
   latexmath:[\frac{\ea_L \notin FV(A) \quad \expr{\Gamma[\ea_L\]}{\subtype{\ea_L}{A}}{\Delta}}{\expr{\Gamma[\ea_L\]}{\ea_L\ <:\ A}{\Delta}}] [green]+<:InstantiateL+
   latexmath:[\quad\quad]
   latexmath:[\frac{\ea_L \notin FV(A) \quad \expr{\Gamma[\ea_L\]}{\subtype{A}{\ea_L}}{\Delta}}{\expr{\Gamma[\ea_L\]}{A\ <:\ \ea_L}{\Delta}}] [green]+<:InstantiateR+
>| latexmath:[\text{subtype} :: A \rightarrow B \rightarrow \Gamma \rightarrow \Delta]
|===

Type variables in different languages have no subtype relationship. As far as
the typechecker goes, it is assumed that the language-specific (concrete) types
match if the general types do. Note that functions are not annotated with
languages. Thus the subtype test latexmath:[A \rightarrow B\ <:\ \alpha_L] and its reverse
will both raise errors.

The rule +<:AlienExvar+ stores in context an "existential assertion" that
cannot be evaluated until the existential variables it contains are solved.

Parameterized types across languages is supported. This may seem impossible,
since not all languages support parameterized types. This is easiest to explain
with examples showing general, Haskell, `C++`, python and R signatures.

.map of strings to integers
[source,bash]
----
x :: Map String Integer
x Haskell :: "Map $1 $2" String Integer
x C++ :: "std::map<$1,$2>" "std::string" int
x Python :: "dict" str int
x R :: "list" str int
----

To allow for different syntax for paramterization across languages, the first
term is a pattern that takes the parameters as arguments. For Haskell and
`C++`, the parameterized types would ultimately be formed into `Map String
Integer` and `std::map<std::string,int>`, respectively. For dynamic languages,
the parameters will not appear in final type itself (`dict` and `list`,
respectively), but the type information will be preserved.

.Instantiation Rules
|===
<| latexmath:[\expr{\Gamma}{\subtype{\ea_L}{A}}{\Delta}] latexmath:[\quad\quad] Under input context latexmath:[\Gamma], instantiate latexmath:[\ea_L] such that latexmath:[\ea_L <: A], with output context latexmath:[\Delta]
^| latexmath:[\frac{\Gamma\ \vdash\ \tau}{\expr{\Gamma,\ea_L,\Gamma'}{\subtype{\ea_L}{\tau}}{\Gamma,\ea_L=\tau,\Gamma'}}] [green]+InstLSolve+
   latexmath:[\quad\quad]
   latexmath:[\frac{}{\expr{\Gamma[\ea_L\][\eb_L\]}{\subtype{\ea_L}{\eb_L}}{\Gamma[\ea_L\][\eb=\ea_L\]}}] [green]+InstLReach+
   +
   +
   latexmath:[\frac{\expr{\Gamma[\ea_2,\ea_1,\ea=\ea_2\rightarrow\ea_1\]}{\subtype{A_1}{\ea_1}}{\Theta} \quad \expr{\Theta}{\subtype{\ea_2}{[\Theta\]A_2}}{\Delta}}{\expr{\Gamma[\ea\]}{\subtype{\ea}{A_1 \rightarrow A_2}}{\Delta}}] [green]+InstLArr+
   latexmath:[\quad\quad]
   latexmath:[\frac{\expr{\Gamma[\ea_L\],\beta_L}{\subtype{\ea_L}{B}}{\Delta,\beta_L,\Delta'}}{\expr{\Gamma[\ea_L}{\subtype{\ea_L}{\forall \beta_L . B}}{\Delta}}] [green]+InstLAllR+
^| latexmath:[\frac{\Gamma\ \vdash\ \tau}{\expr{\Gamma,\ea_L,\Gamma'}{\subtype{\tau}{\ea_L}}{\Gamma,\ea_L=\tau,\Gamma'}}] [green]+InstRSolve+
   latexmath:[\quad\quad]
   latexmath:[\frac{}{\expr{\Gamma[\ea_L\][\eb_L\]}{\subtype{\eb_L}{\ea_L}}{\Gamma[\ea_L\][\eb_L=\ea_L\]}}] [green]+InstRReach+
   +
   +
   latexmath:[\frac{\expr{\Gamma[\ea_{L,2},\ea_{L,1},\ea_L=\ea_{L,2}\rightarrow\ea_{L,1}\]}{\subtype{\ea_{L,1}}{A_1}}{\Theta}  \quad  \expr{\Theta}{\subtype{[\Theta\]A_2}{\ea_{L,2}}}{\Delta}}{\expr{\Gamma[\ea_L\]}{\subtype{A_1 \rightarrow A_2}{\ea}}{\Delta}}] [green]+InstRArr+
   latexmath:[\quad\quad]
   latexmath:[\frac{\expr{\Gamma[\ea_L\],\ \blacktriangleright \eb_L,\ \eb_L}{\subtype{[\eb_L/\beta_L\]B}{\ea_L}}{\Delta,\ \blacktriangleright \eb_L,\ \Delta'}}{\expr{\Gamma[\ea_L\]}{\subtype{\forall \beta_L . B}{\ea_L}}{\Delta}}] [green]+InstRAllL+
>| latexmath:[\text{instantiate}\ ::\ A \rightarrow B \rightarrow \Gamma \rightarrow \Delta]
|===

The instantiation rules above are identical to the rules from DK. However, in
`morloc`, existential types additionally carry parameters and default values.

.Transform rules

|===
<| latexmath:[\packto{A_{L1}}{B_{L2}}] latexmath:[\quad\quad] Type latexmath:[A] in language latexmath:[L1] can be uniquely transformed to type latexmath:[B] in language latexmath:[L2] 
^| latexmath:[\frac{}{\expr{\Gamma}{\packto{A_L}{A_L}}{\Gamma}}] [green]+SerializeCis+
   latexmath:[\quad\quad]
   latexmath:[\frac {f\ L_1\ ::\ \text{packs}\ \Rightarrow\ A'_{L1}\ \rightarrow\ C_{L1} \quad g\ L_2\ ::\ \text{unpacks}\ \Rightarrow\ D_{L2}\ \rightarrow\ B'_{L2} \quad \subtype{A'_{L1}}{A_{L1}} \quad \subtype{B'_{L1}}{B_{L1}}} {\expr{\Gamma}{\packto{A_{L1}}{B_{L2}}}{\Gamma}}] [green]+SerializeTrans+
   +
   +
   latexmath:[\frac{f\ L\ ::\ \text{cast}\ \Rightarrow\ A_L\ \rightarrow\ X_L \quad \packto{X_L}{B_L}}{\expr{\Gamma}{\packto{A_{L}}{B_{L}}}{\Gamma}}] [green]+Cast+
>| latexmath:[\text{cast}\ ::\ A\ \rightarrow\ B\ \rightarrow\ \Gamma\ \rightarrow\ \Gamma]
|===

The transform rules assert that types are interconvertible. The serialization
rules transform between semantically equivalent types that are expressed in
different languages. The cast rules transform between semantically different
types expressed in the same language.

+SerializeCis+ is a trivial rule stating that any type can be converted to
itself. +SerializeTrans+ states that types latexmath:[A_{L1}] and latexmath:[A_{L2}] interconverted
if there exist functions for serializing from type latexmath:[A] in language latexmath:[L_1] to a
standard intermediate form (e.g., JSON) and a derserialization function from
the standard intermediate to latexmath:[B] in language latexmath:[L_2]. The serialization function
may be more polymorphic than latexmath:[A] and latexmath:[B]. For example, a general serialization
function may exist which would serialiaze any type in the given language into
JSON.

These assertions alone are not sufficient for proving that two types are
interconvertible. The serialization functions show only that a path exists
between the types (e.g., they serialize to a common JSON object), it does not
show that the types are semantically equivalent. Semantic equivalence is
demonstrated through typechecking of the general, language-independent, type.
That is, if the language-specific types under consideration are not
semantically equivalent, and error will be raised elsewhere in the typechecking
process.

Prior to `morloc` v0.22.0, I explicitly wrote serialization functions with
`morloc` signatures using the `pack`/`unpack` property. In v0.22.0, I replaced
this system with a language-specific approach of passing some form of
type-template to the serialization machinery particular to the given language.
This means serialization is up to the libraries in the specific languages and
the type checker will not be able to catch the absence of a serialization path.
This approach has worked well, but I am not happy with the absence of static
checks or with how awkward it is to explain.

The +Cast+ rule involves handling of directed automatic conversions between
types within a language. A common example of this would be the conversion of
integers to doubles. The current rules are very strict, requiring type identity
for casting, and are not amiable to more general transformations. Note the rule
is recursive. The cast functions form a directed graph (usually highly
disconnected and possibly cyclic) of unambiguous and unfailing transformations
between types. They should describe relationships where there is a single
obvious meaning (e.g., +a->[a]+ or +PositiveInteger->Integer+) and that will
never fail (so string to integer would not be included).

Further, the rules specified here are assertions showing the transformations
are possible. There may be multiple paths to accomplishing the transforms that
will differ in performance and require different dependencies at build time.
Choosing which path to take is not the responsibility of the typechecker and
will be dependent on the user's system architecture and local configuration.


.synthesize
|===
<| latexmath:[\expr{\Gamma}{e \Rightarrow A}{\Delta}] latexmath:[\quad\quad] Under input context latexmath:[\Gamma], latexmath:[e] synthesizes output type latexmath:[A], with output context latexmath:[\Delta]
^| latexmath:[\frac{\expr{\Gamma, x:A_L}{e_2\ \Rightarrow\ \_}{\Delta}}{\expr{\Gamma}{x\ L\ ::\ A_L\ ;\ e_2}{\Delta}}] [blue]+Signature+
   latexmath:[\quad\quad]
   latexmath:[\frac{}{\expr{\Gamma}{\text{Source }L\ x}{\Gamma,\ \ea_L}}] [blue]+Source+
   +
   +
   latexmath:[\frac{e\ \Rightarrow\ \_\ \vdash\ \Theta \quad \lbrace x:A\ \|\ (x:A)\ \in\ \Theta \rbrace\ \vdash\ \Theta' \quad \lbrace x:A\ \|\ x\ \in\ xs,\ (x:A) \in \Theta' \rbrace\ \vdash\ \Delta}{\expr{\Gamma}{\text{Import}\ e\ xs}{\Gamma, \Delta}}] [red]+Import+
   +
   +
   latexmath:[\frac{x \notin \text{FV}(\Gamma) \quad \expr{\Gamma[x:A\], \mark{x}}{e\ \Leftarrow\ A}{\Delta,\mark{x}, \Theta}}{\expr{\Gamma}{x=e}{\Delta}}] [blue]+DeclareCheck+
   latexmath:[\quad\quad]
   latexmath:[\frac{x \notin \text{FV}(\Gamma) \quad \expr{\Gamma,\mark{x}}{e\ \Rightarrow\ A}{\Delta,\mark{x}, \Theta}}{\expr{\Gamma}{x=e}{\Delta,\ x:\text{Gen}(A)}}] [blue]+DeclareInfer+
>| latexmath:[\text{synthesizeToplevel} :: \Gamma \rightarrow e \rightarrow \Delta]

^| latexmath:[\frac{L = \text{MLang}}{\expr{\Gamma}{\text{number}\ \Rightarrow\ \text{Num}}{\Gamma}}] [blue]+Num⇒+
   latexmath:[\quad\quad]
   latexmath:[\frac{L = \text{MLang}}{\expr{\Gamma}{\text{int} \Rightarrow \text{Int}}{\Gamma}}] [blue]+Int⇒+
   latexmath:[\quad\quad]
   latexmath:[\frac{L = \text{MLang}}{\expr{\Gamma}{\text{string} \Rightarrow \text{Str}}{\Gamma}}] [blue]+Str⇒+
   latexmath:[\quad\quad]
   latexmath:[\frac{L = \text{MLang}}{\expr{\Gamma}{\text{bool} \Rightarrow \text{Bool}}{\Gamma}}] [blue]+Bool⇒+
   +
   +
   latexmath:[\frac{L = \text{MLang} \quad \expr{\Gamma}{x_1 \Rightarrow A}{\Delta_1} \quad \expr{\Delta_1}{x_2 \Leftarrow A}{\Delta_2} \quad ... \quad \expr{\Delta_{n-1}}{x_n \Leftarrow A}{\Delta_n}}{\expr{\Gamma}{[x_1,x_2, ..., x_n\]}{\Delta_n,\ \text{List}\ A}}] [blue]+List⇒+
   +
   +
   latexmath:[\frac{L = \text{MLang} \quad \expr{\Gamma}{x_1 \Rightarrow A_1}{\Delta_1} \quad ... \quad \expr{\Delta_{n-1}}{x_n \Rightarrow A_n}{\Delta_n}}{\expr{\Gamma}{(x_1,x_2,\ ...\ x_n)}{\Delta_n,\ \text{Tuple}\ A_1\ ...\  A_n}}] [blue]+Tuple⇒+
   +
   +
   latexmath:[\frac{L = \text{MLang} \quad \expr{\Gamma}{x_1 \Rightarrow A_1}{\Delta_1} \quad ... \quad \expr{\Delta_{n-1}}{x_n \Rightarrow A_n}{\Delta_n}}{\expr{\Gamma}{\lbrace (k_1,x_1),(k_2, x_2),\ ...,\ (k_n, x_n) \rbrace}{\Delta_n,\ \lbrace (k_1, A_1),\ ...,\  (k_n, A_n) \rbrace}}] [blue]+Record⇒+
   +
   +
   latexmath:[\frac{L \quad \expr{\Gamma,\ea_L,\eb_L,x:\ea_L}{e \Leftarrow \eb_L}{\Delta, x:\ea_L, \Theta}}{\expr{\Gamma}{\lambda x.e\ \Rightarrow\ \ea_L\rightarrow \eb_L}{\Delta}}] [green]+→I⇒+
>| latexmath:[\text{synthesizeSingular} :: L \rightarrow \Gamma \rightarrow e \rightarrow (\Delta,\ A)]

^| latexmath:[\frac{(\,x\,:\,A_L\,)\ \in\ \vec{A}\ \in\ \Gamma}{\expr{\Gamma}{x\ \overset{L}{\Rightarrow} A_L}{\Gamma}}] [green]+Var+
   latexmath:[\quad\quad]
   latexmath:[\frac{\forall\ M\ .\ (x:A_m)\ \notin\ \vec{A}\ \in\ \Gamma \quad (\,x\,:\,A\,)\ \in\ \vec{A}\ \in\ \Gamma \quad \Gamma\ \vdash\ x=e \quad \expr{\Gamma}{e \overset{L}{\Rightarrow} A_L}{\Delta}}{\expr{\Gamma}{x\ \overset{L}{\Rightarrow} A_L}{\Delta}}] [blue]+Var⇒+
   +
   +
   latexmath:[\frac{\Gamma\ \vdash\ A \quad \Delta_1 = \Gamma \quad \braced{ \expr{\Delta_i}{e \overset{L_i}{\Leftarrow} A_i}{\Delta_{i+1}} }_{i=1}^k}{\expr{\Gamma}{(e:\vec{A})\ \Rightarrow\ \vec{A}}{\Delta}}] [green]+Anno+
   latexmath:[\quad\quad]
   latexmath:[\frac{\expr{\Gamma}{e_1\ \Rightarrow\ \vec{A}}{\Delta} \quad\quad \braced{ \Delta\ \vdash\ [\Delta\] \apply{A_{L_i}}{e_2}{C_{L_i}}\ \|\ L_i \in \text{lang}(\vec{A}) }_{i=1}^k}{\expr{\Gamma}{e_1 e_2 \Rightarrow \vec{C}}{\Delta}}] [green]+→E+
>| latexmath:[\text{synthesizeSpread} :: \Gamma \rightarrow e \rightarrow (\Delta_k,\ [A_L\])]
|===

I added typechecking rules that for primitives, containers, declarations and
signatures. The primitive rules are axioms where the types are inferred by the
lexer. The containers include homogenous lists, tuples, and records. A
declaration allows a variable to be assigned to an expression. Top-level
shadowing is not allowed (i.e. no re-assignment). Also the types are
generalized, with all remaining existential variables pulled out as universal
quantifiers.

The three functions +synthesisToplevel+, +synthesisSingular+, and
+synthesisSpread+ are all specializations of the general functions of type:

`synthesis` +++::+++ +L+ -> +Gamma+ -> +e+ -> +[A]+

Each rule will be described in the sections below.

.synthesisToplevel

The top-level statements import/source terms, specify their type (+Signature+),
and build compositions from them (+Declaration+).

The +Import+ rule is premised on the evalutation of latexmath:[e], which is an entire
module body that yields a full context. The term latexmath:[(A\ \Rightarrow\ \_)] is an
inference that throws away the resulting type, being run only for the context
it generates.

.synthesisSingular

.synthesisSpread

Morloc Data structures can be typed into MLang, but not directly into other
languages without additional information. For example, is +[Num]+ in `C++` an
array or vector? Is Num a "double" or a "float"? Determining the concrete type
will require a concrete type-signature. Thus the concrete types are _checked_
rather than _synthesized_.

Synthesizing a lambda requires we choose a language. Nothing in the body of the
lambda expression specifies the language of the lambda. The language of the
subcomponents may differ from the language of the lambda or may have no
concrete binding at all (e.g., latexmath:[\lambda x . 42]).

The +Var⇒+ rule handles cases where an expression with no concrete type (i.e.,
one that does not make a function call) is assigned to a variable and is then
used in a second expression. For example:

[source,bash]
----
import pybase (map, add)
ys = [1,2,3]
foo x = map (add x) ys 
----

`map` and `add` are both functions imported from Python3. `ys`, though, is
defined as a general list of numbers. At the location where it is defined, no
language can be inferred. It is not until `ys` is called within `foo` that its
concrete type can be inferred.


.check
|===
<| latexmath:[\expr{\Gamma}{e \Leftarrow A}{\Delta}] latexmath:[\quad\quad] Under input context latexmath:[\Gamma], latexmath:[e] checks against input type latexmath:[A], with output context latexmath:[\Delta] 
^| latexmath:[\frac{\expr{\Gamma,x:A_L}{e \Leftarrow B_L}{\Delta,x:A_L,\Theta}}{\expr{\Gamma}{\lambda x.e \Leftarrow A_L \rightarrow B_L}{\Delta}}] [green]+→I+
   latexmath:[\quad\quad]
   latexmath:[\frac{\expr{\Gamma,\alpha_L}{e \Leftarrow A_L}{\Delta,\alpha_L,\Theta}}{\expr{\Gamma}{e \Leftarrow \forall \alpha_L . A_L}{\Delta}}] [green]+∀I+
   latexmath:[\quad\quad]
   latexmath:[\frac{\expr{\Gamma}{e \overset{L}{\Rightarrow} A_L}{\Theta} \quad\quad \expr{\Theta}{[\Theta\]A_L\ <:\ [\Theta\]B_L}{\Delta}}{\expr{\Gamma}{e \Leftarrow B_L}{\Delta}}] [green]+Sub+
   latexmath:[\quad\quad]
>| latexmath:[\text{check} :: \Gamma \rightarrow e \rightarrow A \rightarrow (\Delta,\ B\])]
|===

.apply
|===
<| latexmath:[\expr{\Gamma}{\apply{A}{e}{C}}{\Delta}] latexmath:[\quad\quad] Under latexmath:[\Gamma], applying a function of type latexmath:[A] to latexmath:[e] synthesizes type latexmath:[C], with output context latexmath:[\Delta]
^| latexmath:[\frac{\expr{\Gamma[\ea_{2L},\ \ea_{1L},\ \ea_L\ =\ \ea_{1L}\ \rightarrow\ \ea_{2L}\]}{e \Leftarrow\ \ea_{1L}}{\Delta}}{\expr{\Gamma[\ea_L\]}{\apply{\ea_L}{e}{\ea_{2L}}}{\Delta}}] [green]*latexmath:[\ea_L]*[green]+App+
   latexmath:[\quad\quad]
   latexmath:[\frac{\expr{\Gamma,\ea_L}{\apply{[\ea_L/\alpha_L\]A}{e}{C}}{\Delta}}{\expr{\Gamma}{\apply{\forall\alpha_L . A}{e}{C}}{\Delta}}] [green]+∀App+
   latexmath:[\quad\quad]
   latexmath:[\frac{\expr{\Gamma}{e \Leftarrow A}{\Delta}}{\expr{\Gamma}{\apply{A \rightarrow C}{e}{C}}{\Delta}}]  [green]+→App+
   latexmath:[\quad\quad]
>| latexmath:[\text{apply} :: \Gamma \rightarrow e \rightarrow A \rightarrow (\Delta,\ [(L,\ B)\])]
|===


== Let polymorphism

We depart from Hindley-Milner (HM) by excluding a +let+ term. In HM,
expressions bound in +let+ are generalized, allowing statements such as:

----
let f = (forall a . a -> a) in
    x = (f 42, f "lettuce")
----

Where latexmath:[f] is generalized, allowing it to retain its polymorphism. The same is
not true of variables bound in functions (in HM at least). For example, the
following Haskell expression fails to typecheck:  

----
foo :: (a -> a) -> (Int, String)
foo f = (f 42, f "lettuce")
----

We do not suport +let+ expressions or _let-polymorphism_, instead we generalize
expressions only if they are bound at the top-level (i.e. in +declaration+
terms). This follows the practice argued for in cite:[vytiniotis2010let].
