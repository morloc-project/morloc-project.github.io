=== Shared Memory

Pools in a Morloc program share data through memory-mapped shared memory rather
than copying data over sockets. Only a relative pointer (8 bytes) travels over
the wire; the actual data lives in shared memory accessible to all
processes. This is critical for performance -- in the ideal case, this allows
programs to share data with zero copying or serialization. In practice, copying
is often required. For example, Python demands ownership over its strings, even
when in principle they could be reused directly between languages.

==== Volumes

Shared memory is organized as a **multi-volume pool**. Each volume is a
separate POSIX shared memory segment (visible as `/dev/shm/morloc-<hash>_0`,
`morloc-<hash>_1`, etc.). If `/dev/shm` is too small -- common in Docker
containers -- volumes fall back to regular files in the temporary directory
(`/tmp/morloc.XXXXXX/`).

The first volume is created by the nexus during startup with a default size of
64 KB. When a volume fills up, the allocator automatically creates a new one
(up to 32 volumes). The new volume's size is chosen to be at least as large as
the total existing pool or the requested allocation, whichever is larger,
bounded by available system memory.


==== Pointer types

Morloc uses three pointer types to navigate shared memory. Each serves a
different purpose:

----
             head of volume 1   inter-memory    head of volume 2
              n=6  block1          n=20                block2
         ---xxxxxx........--------------------xxxxxx............---->
         |  |     |      |                    |     |          |
         v  v     v      v                    v     v          v
 absptr  0  4    10     17                   38    44         55
 volptr           0      7                          0         10
 relptr           0      7                          8         19
----

[cols="1, 4"]
|===
| Type | Description

| `absptr_t` (`void*`)
| A virtual address in the current process. Different in every process because
  each process maps shared memory to a different address. Used for direct memory
  access within a single process.

| `volptr_t` (`ssize_t`)
| An offset within a single volume. 0 is the first byte after the `shm_t`
  header. Used internally by the allocator.

| `relptr_t` (`ssize_t`)
| A global offset across all volumes. Volume 0's offsets start at 0; volume 1's
  offsets start at volume 0's size; and so on. **This is the pointer type shared
  between processes** -- it appears in data packets (`source=RPTR`) and in
  Morloc's voidstar data structures.
|===

Conversion functions translate between these types:

* `rel2abs` -- Walks through volumes, subtracting each volume's size from the
  relative pointer until the right volume is found, then computes the virtual
  address.
* `abs2rel` -- Scans volumes to find which one contains the virtual address,
  then computes the global offset.
* `vol2rel` / `rel2vol` -- Convert between volume-local and global offsets using
  each volume's `relative_offset` field.

[mermaid]
....
flowchart LR
    A[absptr_t<br/>per-process virtual address] <-->|abs2vol / vol2abs| B[volptr_t<br/>offset within one volume]
    B <-->|vol2rel / rel2vol| C[relptr_t<br/>global offset across volumes]
    A <-->|abs2rel / rel2abs| C
....


==== Volume structure

Each volume starts with an `shm_t` header (not packed, because it contains a
`pthread_rwlock_t` that requires alignment):

[cols="2, 2, 8"]
|===
| Field | Type | Description

| `magic` | `unsigned int` | Constant `0xFECA0DF0`. Used to verify the volume is valid.
| `volume_name` | `char[256]` | Name of this volume (bare name for POSIX shm, full path for file-backed).
| `volume_index` | `int` | Index of this volume in the pool (0, 1, 2, ...).
| `volume_size` | `size_t` | Usable data capacity in bytes (excludes the `shm_t` header).
| `relative_offset` | `size_t` | Sum of all prior volumes' sizes. Volume 0 has offset 0.
| `rwlock` | `pthread_rwlock_t` | Process-shared read-write lock. Protects block scanning and splitting.
| `cursor` | `volptr_t` | Points to the current free block. Used by the allocator as a fast-path hint.
|===


==== Block headers

Data within a volume is organized into blocks. Every block -- allocated or free
-- starts with a `block_header_t` (packed for stable binary layout):

[cols="2, 2, 8"]
|===
| Field | Type | Description

| `magic` | `unsigned int` | Constant `0x0CB10DF0`. Detects corruption.
| `reference_count` | `atomic unsigned int` | Number of active references. 0 means free.
| `size` | `size_t` | Payload size in bytes (excludes the header itself).
|===

When `shmalloc` returns a pointer, it points to the byte immediately after the
block header. The header can always be recovered by subtracting
`sizeof(block_header_t)` from the data pointer.


==== Allocation (`shmalloc`)

`shmalloc` is the shared-memory equivalent of `malloc`. Its algorithm:

1. **Fast path**: Check if the block at the cursor (the last known free block)
   is large enough. If so, use it immediately.
2. **Volume scan**: If the cursor block is too small or allocated, scan forward
   through the current volume using first-fit. Adjacent free blocks are
   **merged** as they're encountered.
3. **Wrap around**: If the end of the volume is reached, restart the scan from
   the beginning up to the cursor position.
4. **Other volumes**: If no suitable block is found, repeat the scan in other
   existing volumes.
5. **New volume**: If all volumes are full, allocate a new volume and use its
   initial block.

Once a suitable free block is found, `split_block` divides it:

* The requested portion gets `reference_count = 1` and is returned.
* The remainder (if large enough to hold a new block header) becomes a new free
  block, and the cursor is updated to point to it.

All allocation operations are protected by a global `pthread_mutex_t`. The
per-volume `rwlock` protects block scanning and splitting within individual
volumes.

There's also `shrealloc` (grow/shrink in place or relocate), `shcalloc`
(zero-initialized), and `shmemcpy` (allocate + copy).


==== Deallocation (`shfree`)

`shfree` atomically decrements the block's reference count. If it drops to zero,
the block's data is zeroed. The block isn't immediately coalesced -- that
happens lazily during the next `shmalloc` scan, which merges adjacent free
blocks as it walks through the volume.

Reference counting allows multiple consumers to hold references to the same
data. A pool that receives a relative pointer can increment the reference count
if it needs the data to outlive the current call.


==== Lifecycle

The lifecycle of shared memory in a Morloc program:

1. **Nexus creates volume 0**: `shinit("morloc-<hash>", 0, 0xffff)` creates a
   65 KB POSIX shared memory segment (or file-backed fallback) and maps it into
   the nexus process.

2. **Pools map the same volume**: Each pool receives the shared memory basename
   as a command-line argument. On startup, it calls `shinit` (or `shopen`),
   which opens and maps the existing segment. All processes now see the same
   memory.

3. **Data is written via `shmalloc`**: Functions allocate space in shared memory
   and write data there. The allocator may create new volumes as needed.

4. **Relative pointers travel in packets**: When a pool returns a result, it
   packs a `relptr_t` into a data packet (`source=RPTR`). The receiving process
   converts it back to an `absptr_t` via `rel2abs` and reads the data directly.

5. **Cleanup on exit**: The nexus calls `shclose`, which iterates through all
   volumes, destroys their rwlocks, unmaps them, and unlinks the underlying
   shared memory segments (or files). The temporary directory is also deleted.

