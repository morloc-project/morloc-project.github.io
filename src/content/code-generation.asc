
The input to the code generator is a list of bipartite, ambiguous, abstract
syntax trees (AST). There is one tree for each command exported from the root
module. The AST is implemented as a pair of mutually recursive data structures:
`SAnno` and `SExpr`.

`SAnno` associates a set of subtrees with a shared annotation (general type and metadata).

[source, haskell]
----
data SAnno g f c = SAnno (f (SExpr g f c, c)) g
----

Where
 * g - an annotation for the group of child trees (what they have in common)
 * f - a collection type (e.g., `One` or `Many`)
 * c - an annotation for the specific child tree

`SExpr` represents an expression that may have `SAnno` children.

[source, haskell]
----
data SExpr g f c
  = UniS
  | VarS EVar
  | AccS (SAnno g f c) EVar
  | ListS [SAnno g f c]
  | TupleS [SAnno g f c]
  | LamS [EVar] (SAnno g f c)
  | AppS (SAnno g f c) [SAnno g f c]
  | NumS Scientific
  | LogS Bool
  | StrS Text
  | RecS [(EVar, SAnno g f c)]
  | CallS Source
----

=== Rewrite

The `SAnno`s are not quite ready for translation yet. They contain `morloc`
functions on the right-hand-side of equations. Yet these functions are not
"real" and should not appear (except as debugging info) in the final generated
code.

For example, consider the following `morloc` script:

----
import cppbase (mul, add)

export foo

foo x y = bar x (baz y)
bar x y = mul x (add y 1)
baz x = mul x x 
----

The Rewrite step redefines the exported `foo` function by eliminating the `bar`
and `baz` abstractions, as below:

----
foo x y = mul x (add (mul y y) 1)
----

The process is complicated when there are unresolved topology differences. For
example, if `bar` has two definitions, as below:

----
module main (foo)

import cppbase (mul, add, bar)

foo x y = bar x (baz y)
bar x y = mul x (add y 1)
baz x = mul x x 
----

Now `bar` can either be the `morloc` composition or the {cpp} function. So we can
generate two possible forms of `foo`:

----
foo x y = mul x (add (mul y y) 1)
foo x y = bar x (mul y y)
----

The first substitutes `x` and `baz y` into the `morloc` function `bar`. The
latter uses the {cpp} function for `bar`. These two implementations will both be
included under the `Many` in the `SAnno` output.

=== Realize

The `f` in the `SAnno` type takes on two forms in the generator: `One` or `Many`:

[source, haskell]
----
data One a = One a
data Many a = Many [a]
----

The input to the generator is ambiguous, hence `f` is `Many`. The "Realize"
step collapses the tree down to a single "realization" (or "instance"). Thus
the `realize` function, eliding implementation details, has the type: 

[source, haskell]
----
realize :: SAnno g Many Type -> SAnno g One Type
----

Two levels of ambiguity are removed in this step. The `Many` to `One`
transition selects selects a single sub-tree topology. For example, suppose there 

[source]
----
module main (mean)

import math (sum, div, length, mean)
source R ("mean")

mean xs = div (sum xs) (length xs)
----

Here we have three definitions of `mean`. One is sourced from the `R` language
(where it is a built in function). One is sourced from the `morloc math`
module, where it is implemented in C. One is defined as a `morloc` composition of
the three functions `div`, `sum`, and `length`; these are all implemented in C
currently, but they could gain more implementations in the future.

There are *three* definitions of `mean`, and *two* topologies (thus two
elements in `Many`). The topologies are either the `(div (sum xs) (length xs))`
tree or the call to the `R` or `C` functions. The first problem is the
`Many->One` selection. The second problem is the `[Type]->Type` problem, where
the sourced implementation is chosen. Here we decide just between a single `R`
and single `C` function. But the choice could be more involved, such as
choosing between a dozen sort algorithms all written in `C`.

This is the data structure is the starting point for an epic optimization
problem.


=== Optimization

.Algorithm optimization

In the future, when `morloc` is mature, the realization step will incorporate
community knowledge, performance modeling, and benchmarking to make the optimal
decision. For now, I assign a relative cost to each pair of inter-language
calls and find the tree that minimizes the total cost.

The most interesting optimizations involve choices between algorithms. We could
build formal performance models for each algorithm and parameterize them
empirically for each implementation.


.Build optimization

The goal of build optimization is to 1) ensure the program compiles, 2)
minimize the dependencies and 3) tailor the build to the local architecture. In
theory, a `morloc` program can avoid bit-rot and adapt to any architecture so
long as there exists at least one valid tree instance.

I haven't worked on build optimization yet, but I imagine the input to the
mature `morloc` build machine will be a description of the local architecture and
a list of possible ASTs, ordered by expected performance. The machine could
then try to build the "best" tree. If the build fails, the machine then finds
the next highest scoring tree that does not contain the failing component.

Making this process efficient through judicious use of deep knowledge gathered
from the community will be a major focus in the future. The knowledge gained in
one build (e.g., function X failed on OS Y in state Z) could be uploaded
automatically to the community knowledgebase and accessed in future builds.


.Interoperability optimization

The minimization of inter-operability costs is the easiest optimization and the
only one that is currently supported. Program performance can be improved by
reducing the number and cost of foreign calls.

.Penalties for calls between languages
----
          C    Python           R
C         1       100        1000
Python   10         2        1000
R        10       100           3
----

The values in the table above are obviously very rough, but they demonstrate
important principles for optimizing `morloc` programs. Calls within languages
are cheap and between languages are expensive (usually, this would change if we
added support for binary application interfaces). Major performance improvements
could be obtained by removing the start-up costs of loading the R/Python
runtime, for example by passing data to an open R server rather than restarting
R for every call.

